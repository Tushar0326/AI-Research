{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4e7179b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f68f71bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor t1:\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "Shape: torch.Size([2, 2])\n",
      "\n",
      "Tensor t2:\n",
      "tensor([[5., 6.],\n",
      "        [7., 8.]])\n",
      "Shape: torch.Size([2, 2])\n",
      "\n",
      "torch.cat([t1, t2], dim=0) - concatenate along rows:\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.],\n",
      "        [7., 8.]])\n",
      "Shape: torch.Size([4, 2])\n",
      "\n",
      "torch.cat([t1, t2], dim=1) - concatenate along columns:\n",
      "tensor([[1., 2., 5., 6.],\n",
      "        [3., 4., 7., 8.]])\n",
      "Shape: torch.Size([2, 4])\n",
      "\n",
      "Concatenate 3 tensors:\n",
      "tensor([[ 1.,  2.],\n",
      "        [ 3.,  4.],\n",
      "        [ 5.,  6.],\n",
      "        [ 7.,  8.],\n",
      "        [ 9., 10.],\n",
      "        [11., 12.]])\n",
      "Shape: torch.Size([6, 2])\n"
     ]
    }
   ],
   "source": [
    "# Create two tensors\n",
    "t1 = torch.tensor([[1, 2], \n",
    "                   [3, 4]], dtype=torch.float32)\n",
    "\n",
    "t2 = torch.tensor([[5, 6], \n",
    "                   [7, 8]], dtype=torch.float32)\n",
    "\n",
    "print(\"Tensor t1:\")\n",
    "print(t1)\n",
    "print(f\"Shape: {t1.shape}\")\n",
    "print()\n",
    "\n",
    "print(\"Tensor t2:\")\n",
    "print(t2)\n",
    "print(f\"Shape: {t2.shape}\")\n",
    "print()\n",
    "\n",
    "# Concatenate along dimension 0 (stack vertically)\n",
    "t_cat0 = torch.cat([t1, t2], dim=0)\n",
    "print(\"torch.cat([t1, t2], dim=0) - concatenate along rows:\")\n",
    "print(t_cat0)\n",
    "print(f\"Shape: {t_cat0.shape}\")\n",
    "print()\n",
    "\n",
    "# Concatenate along dimension 1 (stack horizontally)\n",
    "t_cat1 = torch.cat([t1, t2], dim=1)\n",
    "print(\"torch.cat([t1, t2], dim=1) - concatenate along columns:\")\n",
    "print(t_cat1)\n",
    "print(f\"Shape: {t_cat1.shape}\")\n",
    "print()\n",
    "\n",
    "# Concatenate multiple tensors\n",
    "t3 = torch.tensor([[9, 10], \n",
    "                   [11, 12]], dtype=torch.float32)\n",
    "t_cat_multiple = torch.cat([t1, t2, t3], dim=0)\n",
    "print(\"Concatenate 3 tensors:\")\n",
    "print(t_cat_multiple)\n",
    "print(f\"Shape: {t_cat_multiple.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c42f791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor t1:\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "Shape: torch.Size([2, 2])\n",
      "\n",
      "Tensor t2:\n",
      "tensor([[5., 6.],\n",
      "        [7., 8.]])\n",
      "Shape: torch.Size([2, 2])\n",
      "\n",
      "torch.stack([t1, t2], dim=0):\n",
      "tensor([[[1., 2.],\n",
      "         [3., 4.]],\n",
      "\n",
      "        [[5., 6.],\n",
      "         [7., 8.]]])\n",
      "Shape: torch.Size([2, 2, 2])\n",
      "(New dimension 0 created!)\n",
      "\n",
      "torch.stack([t1, t2], dim=1):\n",
      "tensor([[[1., 2.],\n",
      "         [5., 6.]],\n",
      "\n",
      "        [[3., 4.],\n",
      "         [7., 8.]]])\n",
      "Shape: torch.Size([2, 2, 2])\n",
      "\n",
      "torch.stack([t1, t2], dim=2):\n",
      "tensor([[[1., 5.],\n",
      "         [2., 6.]],\n",
      "\n",
      "        [[3., 7.],\n",
      "         [4., 8.]]])\n",
      "Shape: torch.Size([2, 2, 2])\n",
      "\n",
      "============================================================\n",
      "COMPARISON: cat vs stack\n",
      "============================================================\n",
      "cat: Concatenates along existing dimension\n",
      "  cat shape: torch.Size([4, 2])\n",
      "\n",
      "stack: Creates new dimension and stacks\n",
      "  stack shape: torch.Size([2, 2, 2])\n",
      "\n",
      "Difference: stack adds a new dimension!\n"
     ]
    }
   ],
   "source": [
    "# Create two tensors\n",
    "t1 = torch.tensor([[1, 2], \n",
    "                   [3, 4]], dtype=torch.float32)\n",
    "\n",
    "t2 = torch.tensor([[5, 6], \n",
    "                   [7, 8]], dtype=torch.float32)\n",
    "\n",
    "print(\"Tensor t1:\")\n",
    "print(t1)\n",
    "print(f\"Shape: {t1.shape}\")\n",
    "print()\n",
    "\n",
    "print(\"Tensor t2:\")\n",
    "print(t2)\n",
    "print(f\"Shape: {t2.shape}\")\n",
    "print()\n",
    "\n",
    "# Stack along dimension 0 (new first dimension)\n",
    "t_stack0 = torch.stack([t1, t2], dim=0)\n",
    "print(\"torch.stack([t1, t2], dim=0):\")\n",
    "print(t_stack0)\n",
    "print(f\"Shape: {t_stack0.shape}\")\n",
    "print(\"(New dimension 0 created!)\")\n",
    "print()\n",
    "\n",
    "# Stack along dimension 1\n",
    "t_stack1 = torch.stack([t1, t2], dim=1)\n",
    "print(\"torch.stack([t1, t2], dim=1):\")\n",
    "print(t_stack1)\n",
    "print(f\"Shape: {t_stack1.shape}\")\n",
    "print()\n",
    "\n",
    "# Stack along dimension 2\n",
    "t_stack2 = torch.stack([t1, t2], dim=2)\n",
    "print(\"torch.stack([t1, t2], dim=2):\")\n",
    "print(t_stack2)\n",
    "print(f\"Shape: {t_stack2.shape}\")\n",
    "print()\n",
    "# Compare: cat vs stack\n",
    "print(\"=\" * 60)\n",
    "print(\"COMPARISON: cat vs stack\")\n",
    "print(\"=\" * 60)\n",
    "print(\"cat: Concatenates along existing dimension\")\n",
    "print(f\"  cat shape: {torch.cat([t1, t2], dim=0).shape}\")\n",
    "print()\n",
    "print(\"stack: Creates new dimension and stacks\")\n",
    "print(f\"  stack shape: {torch.stack([t1, t2], dim=0).shape}\")\n",
    "print()\n",
    "print(\"Difference: stack adds a new dimension!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63375530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature vectors:\n",
      "feature1: tensor([1., 2., 3.])\n",
      "feature2: tensor([4., 5., 6.])\n",
      "feature3: tensor([7., 8., 9.])\n",
      "\n",
      "Stacked into batch:\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.],\n",
      "        [7., 8., 9.]])\n",
      "Shape: torch.Size([3, 3])  (batch_size=3, features=3)\n",
      "\n",
      "Layer outputs:\n",
      "layer1 shape: torch.Size([2, 3])\n",
      "layer2 shape: torch.Size([2, 3])\n",
      "\n",
      "Concatenated features:\n",
      "tensor([[ 1.8862, -0.6076, -0.4660,  1.5749, -0.4939, -0.4293],\n",
      "        [ 1.6981,  0.0429,  0.6983, -1.6400, -1.8981, -0.4417]])\n",
      "Shape: torch.Size([2, 6])  (same rows, doubled columns)\n",
      "\n",
      "Multiple batches:\n",
      "batch1 shape: torch.Size([2, 3])\n",
      "batch2 shape: torch.Size([2, 3])\n",
      "batch3 shape: torch.Size([2, 3])\n",
      "\n",
      "Concatenated batches:\n",
      "Shape: torch.Size([6, 3])  (6 samples, 3 features)\n",
      "\n",
      "Stacked as sequence:\n",
      "Shape: torch.Size([3, 2, 3])  (sequence_length=3, batch_size=2, features=3)\n"
     ]
    }
   ],
   "source": [
    "# Use case 1: Combine feature vectors\n",
    "feature1 = torch.tensor([1, 2, 3], dtype=torch.float32)\n",
    "feature2 = torch.tensor([4, 5, 6], dtype=torch.float32)\n",
    "feature3 = torch.tensor([7, 8, 9], dtype=torch.float32)\n",
    "\n",
    "print(\"Feature vectors:\")\n",
    "print(f\"feature1: {feature1}\")\n",
    "print(f\"feature2: {feature2}\")\n",
    "print(f\"feature3: {feature3}\")\n",
    "print()\n",
    "\n",
    "# Stack to create batch\n",
    "batch = torch.stack([feature1, feature2, feature3], dim=0)\n",
    "print(\"Stacked into batch:\")\n",
    "print(batch)\n",
    "print(f\"Shape: {batch.shape}  (batch_size=3, features=3)\")\n",
    "print()\n",
    "\n",
    "# Use case 2: Concatenate layers\n",
    "layer1 = torch.randn(2, 3)\n",
    "layer2 = torch.randn(2, 3)\n",
    "\n",
    "print(\"Layer outputs:\")\n",
    "print(f\"layer1 shape: {layer1.shape}\")\n",
    "print(f\"layer2 shape: {layer2.shape}\")\n",
    "print()\n",
    "\n",
    "# Concatenate features (horizontal)\n",
    "features_concat = torch.cat([layer1, layer2], dim=1)\n",
    "print(\"Concatenated features:\")\n",
    "print(features_concat)\n",
    "print(f\"Shape: {features_concat.shape}  (same rows, doubled columns)\")\n",
    "print()\n",
    "\n",
    "# Use case 3: Stack for batch processing\n",
    "batch1 = torch.randn(2, 3)\n",
    "batch2 = torch.randn(2, 3)\n",
    "batch3 = torch.randn(2, 3)\n",
    "print(\"Multiple batches:\")\n",
    "print(f\"batch1 shape: {batch1.shape}\")\n",
    "print(f\"batch2 shape: {batch2.shape}\")\n",
    "print(f\"batch3 shape: {batch3.shape}\")\n",
    "print()\n",
    "\n",
    "# Stack to create larger batch\n",
    "large_batch = torch.cat([batch1, batch2, batch3], dim=0)\n",
    "print(\"Concatenated batches:\")\n",
    "print(f\"Shape: {large_batch.shape}  (6 samples, 3 features)\")\n",
    "print()\n",
    "\n",
    "# Or stack to create sequence\n",
    "sequence = torch.stack([batch1, batch2, batch3], dim=0)\n",
    "print(\"Stacked as sequence:\")\n",
    "print(f\"Shape: {sequence.shape}  (sequence_length=3, batch_size=2, features=3)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3654510e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
